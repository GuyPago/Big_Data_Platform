{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81dd8969",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Big Data Platform - HW1</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">Guy Taggar - 206260762</p>\n",
    "### <p style=\"text-align: center;\">Ayala Raanan - 040474934</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e48c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as csv\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fb743",
   "metadata": {},
   "source": [
    "### **Task 0** - Create CSV file\n",
    "After defining `fruits` and `colors` as lists of the required fruit and colors, we create the required csv file as `mydata.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256ba562",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['Orange', 'Grape', 'Apple', 'Banana', 'Pineapple', 'Avocado']\n",
    "colors = ['Red', 'Green', 'Yellow', 'Blue']\n",
    "rows = 1000000\n",
    "[i]\n",
    "df = pd.DataFrame({'id': np.arange(1, rows + 1),\n",
    "                   'fruit': np.random.choice(fruits, rows),\n",
    "                   'price': np.random.randint(10, 101, rows),\n",
    "                   'color': np.random.choice(colors, rows)})\n",
    "df.to_csv('mydata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26f512",
   "metadata": {},
   "source": [
    "### **Task 1** - CSV and SQL\n",
    "**1.a**.\tWe create mydb.db using python’s integration with SQLite, and create a new table `mydata` which holds the same scheme as `fruits.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a322ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('mydb.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''\n",
    "          CREATE TABLE mydata (\n",
    "          id INT,\n",
    "          fruit VARCHAR(20),\n",
    "          price INT,\n",
    "          color VARCHAR(20)\n",
    "          )''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20074376",
   "metadata": {},
   "source": [
    "**1.b**. Append the fruits dataframe into `mydata` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('mydata', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4f208",
   "metadata": {},
   "source": [
    "**1.c**. Consider the following SQL statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475395e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orange</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Orange</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Apple</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999966</th>\n",
       "      <td>Pineapple</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999973</th>\n",
       "      <td>Apple</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999989</th>\n",
       "      <td>Orange</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999990</th>\n",
       "      <td>Orange</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999993</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131067 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fruit  price\n",
       "id                      \n",
       "1          Orange     96\n",
       "4           Apple     92\n",
       "7           Apple     98\n",
       "8          Orange     90\n",
       "12          Apple     89\n",
       "...           ...    ...\n",
       "999966  Pineapple     93\n",
       "999973      Apple     94\n",
       "999989     Orange     89\n",
       "999990     Orange     91\n",
       "999993    Avocado     91\n",
       "\n",
       "[131067 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ('''SELECT id, fruit, price  -- Projection\n",
    "          FROM mydata\n",
    "          WHERE price > 88  -- Predicate''')\n",
    "\n",
    "pd.read_sql_query(query, conn, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b609d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>45</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998356</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998861</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>10</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998894</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999702</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999894</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131965 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fruit  price   color\n",
       "id                            \n",
       "850       Apple     45  Yellow\n",
       "1074      Apple     45   Green\n",
       "1143      Apple     45   Green\n",
       "1335      Apple     45   Green\n",
       "1454    Avocado     45   Green\n",
       "...         ...    ...     ...\n",
       "998356    Apple     10  Yellow\n",
       "998861  Avocado     10     Red\n",
       "998894  Avocado     10  Yellow\n",
       "999702    Apple     10     Red\n",
       "999894    Apple     10     Red\n",
       "\n",
       "[131965 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ('''SELECT * FROM mydata  -- Projection\n",
    "            WHERE fruit LIKE \"A%\" and price <= 45  --Predicate\n",
    "            ORDER BY price DESC''')\n",
    "\n",
    "pd.read_sql_query(query, conn, index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac83de",
   "metadata": {},
   "source": [
    "### **Task 2** - CSV and Parquet\n",
    "**2.a**. Consider the following commands that read `mydata.csv` and count the number of lines (rows) in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44258fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mydata.csv', index_col='id')\n",
    "df.shape[0] + 1  # Include the title row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6b170",
   "metadata": {},
   "source": [
    "**2.b**. Using PyArrow, we create a Parquet file named `mydatapyarrow.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = csv.read_csv('mydata.csv')\n",
    "pq.write_table(table, 'parquet_files/mydatapyarrow.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af454211",
   "metadata": {},
   "source": [
    "**2.c**. Using Pandas, we create a parquet file named `mydatapandas.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e2b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('parquet_files/mydatapandas.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dafd5",
   "metadata": {},
   "source": [
    "**2.d**. Using Dask, we create a parquet file named `mydatadask.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeca1fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('mydata.csv').set_index('id')\n",
    "df.to_parquet('parquet_files/mydatadask.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ea56b",
   "metadata": {},
   "source": [
    "**2.e**. While PyArrow and Pandas both generated a pure `.parquet` file, Dask created an entire folder featuring 3 seperate files, one of them is a `.parquet` file. This is probably due to the parallelism that Dask offers. It also created metadata as seperate files, as opposed to PyArrow and Pandas which have the metadata built in the parquet file itself. The main drawback is that Dask's file is almost as twice as large as the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f746062",
   "metadata": {},
   "source": [
    "### **Task 3** - Split CSV files\n",
    "**3.a**. Let us calculate the size of `mydata.csv` in bytes.<br>\n",
    "We define `middle` to be half of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beef4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23732830"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('mydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29bbbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = os.path.getsize('mydata.csv') // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540163db",
   "metadata": {},
   "source": [
    "**3.b**. Consider the following functions, used to count the number of rows in the first and last half of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc893869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_chunk(file, middle=middle, ret_f=False):\n",
    "    with open(file, 'rb') as f:   \n",
    "        d = f.readlines(middle)\n",
    "    if ret_f:\n",
    "        return d, len(d)\n",
    "    return len(d)\n",
    "    \n",
    "def last_chunk(file, middle=middle, ret_f=False):\n",
    "    with open(file, 'rb') as f:\n",
    "        f.seek(middle+1, 0)\n",
    "        d = f.readlines()\n",
    "    if ret_f:\n",
    "        return d, len(d)\n",
    "    return len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544da02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1, d1_len = first_chunk('mydata.csv', ret_f=True)\n",
    "d2, d2_len = last_chunk('mydata.csv', ret_f=True)\n",
    "d1_len + d2_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaf91a",
   "metadata": {},
   "source": [
    "**3.c**. Note that `d1+d2` sum to more than the number of rows in the file. This is because the chunks get conflicted in the concatenation point, hence count the same row twice (or part of it).<br>\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0097c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mydata_2.csv', 'r') as f:\n",
    "    r = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb75604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'502342,Pineapple,20,Blue\\r\\n'\n",
      "b'Blue\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "print(d1[-1])  # 2\n",
    "print(d2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31624f6f",
   "metadata": {},
   "source": [
    "**3.d**. We implement the following algorithm to solve this issue. It checks if the index of the first row of a chunk is the successor of the previous chunk's last row. If it isn't, it gets dropped. The fix occurs In-Place. Note - we assume here that the id's are ordered and incrementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d77a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_chunks(chunks):\n",
    "    '''\n",
    "    Fixes all conflicts within a list of ordered chunks\n",
    "    ----------\n",
    "    Parameters:\n",
    "    chunks: list, a list of all ordered chunks\n",
    "    Each chunk should contain rows in bytes\n",
    "    '''\n",
    "    \n",
    "    #  Drops conflicts in all concatenation points\n",
    "    for chunk in range(len(chunks)-1):\n",
    "        d1 = chunks[chunk][-1].split(b',')\n",
    "        d2 = chunks[chunk+1][0].split(b',')\n",
    "        \n",
    "        d1_last = d1[0]\n",
    "        d2_first = d2[0]\n",
    "        try:\n",
    "            if int(d1_last) != (int(d2_first) - 1) or len(d1) != len(d2):\n",
    "                chunks[chunk+1].pop(0)\n",
    "                \n",
    "        except ValueError:\n",
    "            chunks[chunk+1].pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117139b",
   "metadata": {},
   "source": [
    "Let us test `fix_chunks` on `d1` and `d2`. Note that we can apply it as much as we want, since dropouts occur only if the conflicts conditions hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ecd36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_chunks([d1,d2])\n",
    "len(d1) + len(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdc838",
   "metadata": {},
   "source": [
    "**3.e**. We define the following function to split a file to multiple chunks, each with a size of `c_size`MB by default. Note that `fix_chunks` is being used before returning the chunks, hence the returned chunks are already fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(file, c_size=16):\n",
    "    chunk_size = int(c_size * 1000000)\n",
    "    f_size = os.path.getsize(file)\n",
    "    batches = int(f_size // chunk_size) if f_size % chunk_size == 0 else int(f_size // chunk_size + 1)\n",
    "    chunks = []\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        for i in range(batches):\n",
    "            chunks.append(f.readlines(chunk_size))\n",
    "    fix_chunks(chunks)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2780ce",
   "metadata": {},
   "source": [
    "As the previous example is similar to the base case (of 16MB for 2 chunks), we choose to test it on 2MB chunks.\n",
    "\n",
    "Please feel free to change `c_size` to fit your tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474d80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 12 chunks sum to 1000001 rows.\n"
     ]
    }
   ],
   "source": [
    "chunks = to_chunks('mydata.csv', 2)\n",
    "s = 0\n",
    "for chunk in chunks:\n",
    "    s += len(chunk)\n",
    "print('All', len(chunks), 'chunks sum to', s, 'rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f87ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()  # Close SQL connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
