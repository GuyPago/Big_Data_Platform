{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81dd8969",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Big Data Platform - HW1</p>\n",
    "\n",
    "## <p style=\"text-align: center;\">Guy Taggar</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e48c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as csv\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fb743",
   "metadata": {},
   "source": [
    "### **Task 0** - Create CSV file\n",
    "After defining `fruits` and `colors` as lists of the required fruit and colors, we create the required csv file as `mydata.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256ba562",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['Orange', 'Grape', 'Apple', 'Banana', 'Pineapple', 'Avocado']\n",
    "colors = ['Red', 'Green', 'Yellow', 'Blue']\n",
    "rows = 1000000\n",
    "\n",
    "df = pd.DataFrame({'id': np.arange(1, rows + 1),\n",
    "                   'fruit': np.random.choice(fruits, rows),\n",
    "                   'price': np.random.randint(10, 101, rows),\n",
    "                   'color': np.random.choice(colors, rows)})\n",
    "df.to_csv('mydata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26f512",
   "metadata": {},
   "source": [
    "### **Task 1** - CSV and SQL\n",
    "**1.a**.\tWe create mydb.db using python’s integration with SQLite, and create a new table `mydata` which holds the same scheme as `fruits.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a322ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('mydb.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''\n",
    "          CREATE TABLE mydata (\n",
    "          id INT,\n",
    "          fruit VARCHAR(20),\n",
    "          price INT,\n",
    "          color VARCHAR(20)\n",
    "          )''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20074376",
   "metadata": {},
   "source": [
    "**1.b**. Append the fruits dataframe into `mydata` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('mydata', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4f208",
   "metadata": {},
   "source": [
    "**1.c**. Consider the following SQL statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475395e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pineapple</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pineapple</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999967</th>\n",
       "      <td>Grape</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999971</th>\n",
       "      <td>Banana</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999972</th>\n",
       "      <td>Orange</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999985</th>\n",
       "      <td>Grape</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999989</th>\n",
       "      <td>Orange</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            fruit  price\n",
       "id                      \n",
       "4       Pineapple     98\n",
       "5           Apple     92\n",
       "8       Pineapple     94\n",
       "11          Apple    100\n",
       "13        Avocado     97\n",
       "...           ...    ...\n",
       "999967      Grape     94\n",
       "999971     Banana     90\n",
       "999972     Orange     97\n",
       "999985      Grape     94\n",
       "999989     Orange     94\n",
       "\n",
       "[131608 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ('''SELECT id, fruit, price  -- Projection\n",
    "          FROM mydata\n",
    "          WHERE price > 88  -- Predicate''')\n",
    "\n",
    "pd.read_sql_query(query, conn, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b609d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>45</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>45</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Apple</td>\n",
       "      <td>45</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999258</th>\n",
       "      <td>Avocado</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999267</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999524</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999617</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999831</th>\n",
       "      <td>Apple</td>\n",
       "      <td>10</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fruit  price   color\n",
       "id                            \n",
       "70      Avocado     45  Yellow\n",
       "397       Apple     45     Red\n",
       "501     Avocado     45    Blue\n",
       "887       Apple     45     Red\n",
       "1456      Apple     45  Yellow\n",
       "...         ...    ...     ...\n",
       "999258  Avocado     10  Yellow\n",
       "999267    Apple     10     Red\n",
       "999524    Apple     10   Green\n",
       "999617    Apple     10    Blue\n",
       "999831    Apple     10   Green\n",
       "\n",
       "[131916 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = ('''SELECT * FROM mydata  -- Projection\n",
    "            WHERE fruit LIKE \"A%\" and price <= 45  --Predicate\n",
    "            ORDER BY price DESC''')\n",
    "\n",
    "pd.read_sql_query(query, conn, index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac83de",
   "metadata": {},
   "source": [
    "### **Task 2** - CSV and Parquet\n",
    "**2.a**. Consider the following commands that read `mydata.csv` and count the number of lines (rows) in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44258fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mydata.csv', index_col='id')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6b170",
   "metadata": {},
   "source": [
    "**2.b**. Using PyArrow, we create a Parquet file named `mydatapyarrow.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc682dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = csv.read_csv('mydata.csv')\n",
    "pq.write_table(table, 'parquet_files/mydatapyarrow.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af454211",
   "metadata": {},
   "source": [
    "**2.c**. Using Pandas, we create a parquet file named `mydatapandas.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e2b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('parquet_files/mydatapandas.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dafd5",
   "metadata": {},
   "source": [
    "**2.d**. Using Dask, we create a parquet file named `mydatadask.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeca1fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('mydata.csv').set_index('id')\n",
    "df.to_parquet('parquet_files/mydatadask.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ea56b",
   "metadata": {},
   "source": [
    "**2.e**. While PyArrow and Pandas both generated a pure `.parquet` file, Dask created an entire folder featuring 3 seperate files, one of them is a `.parquette` file. This is probably due to the parallelism that Dask offers. It also created metadata as seperate files, as opposed to PyArrow and Pandas which have the metadata built in the parquet file itself. The main drawback is that Dask's file is almost as twice as large as the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f746062",
   "metadata": {},
   "source": [
    "### **Task 3** - Split CSV files\n",
    "**3.a**. Let us calculate the size of `mydata.csv` in bytes.<br>\n",
    "We define `middle` to be half of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beef4f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23732743"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('mydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29bbbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = os.path.getsize('mydata.csv') // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540163db",
   "metadata": {},
   "source": [
    "**3.b**. Consider the following functions, used to count the number of rows in the first and last half of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc893869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_chunk(file, middle=middle, ret_f=False):\n",
    "    with open(file, 'rb') as f:   \n",
    "        d = f.readlines(middle)\n",
    "    if ret_f:\n",
    "        return d, len(d)\n",
    "    return len(d)\n",
    "    \n",
    "def last_chunk(file, middle=middle, ret_f=False):\n",
    "    with open(file, 'rb') as f:\n",
    "        f.seek(middle+1, 0)\n",
    "        d = f.readlines()\n",
    "    if ret_f:\n",
    "        return d, len(d)\n",
    "    return len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544da02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1, d1_len = first_chunk('mydata.csv', ret_f=True)\n",
    "d2, d2_len = last_chunk('mydata.csv', ret_f=True)\n",
    "d1_len + d2_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdaf91a",
   "metadata": {},
   "source": [
    "**3.c**. Note that `d1+d2` sum to more than the number of rows in the file. There are 2 reasons for that:\n",
    "1. The first chunk collects the title row.\n",
    "2. The chunks get conflicted in the connection point, hence count the same row twice (or part of it).<br>\n",
    "\n",
    "Proof:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c2eef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'id,fruit,price,color\\r\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[0]  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb75604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'502365,Orange,68,Green\\r\\n'\n",
      "b'02365,Orange,68,Green\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "print(d1[-1])  # 2\n",
    "print(d2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31624f6f",
   "metadata": {},
   "source": [
    "**3.d**. We implement the following algorithm to solve this issue. It checks if the index of the first row of a chunk is the successor of the previous chunk's last row. If it isn't, it gets dropped. The fix occurs In-Place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d77a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_chunks(chunks):\n",
    "    '''\n",
    "    Fixes all conflicts within a list of ordered chunks\n",
    "    ----------\n",
    "    Parameters:\n",
    "    chunks: list, a list of all ordered chunks\n",
    "    Each chunk should contain rows in bytes\n",
    "    '''\n",
    "    # Drop column row if exists\n",
    "    try:   \n",
    "        int(chunks[0][0].split(b',')[0])\n",
    "    except ValueError:\n",
    "        chunks[0].pop(0)\n",
    "    \n",
    "    #  Drops conflicts in all concatenation points\n",
    "    for chunk in range(len(chunks)-1):\n",
    "        d1_last = chunks[chunk][-1].split(b',')[0]\n",
    "        d2_first = chunks[chunk+1][0].split(b',')[0]\n",
    "        try:\n",
    "            if int(d1_last) != (int(d2_first) - 1):\n",
    "                chunks[chunk+1].pop(0)\n",
    "        except ValueError:\n",
    "            chunks[chunk+1].pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d117139b",
   "metadata": {},
   "source": [
    "Let us test `fix_chunks` on `d1` and `d2`. Note that we can apply it as much as we want, since dropouts occur only if the conflicts conditions hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ecd36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_chunks([d1,d2])\n",
    "len(d1) + len(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdc838",
   "metadata": {},
   "source": [
    "**3.e**. We define the following function to split a file to multiple chunks, each with a size of `c_size`MB by default. Note that `fix_chunks` is being used before returning the chunks, hence the returned chunks are already fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(file, c_size=16):\n",
    "    chunk_size = c_size * 1000000\n",
    "    f_size = os.path.getsize(file)\n",
    "    batches = f_size // chunk_size + 1 \n",
    "    chunks = []\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        for i in range(1, batches+1):\n",
    "            chunks.append(f.readlines(chunk_size))\n",
    "    fix_chunks(chunks)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2780ce",
   "metadata": {},
   "source": [
    "As the previous example is similar to the base case (of 16MB for 2 chunks), we choose to test it on 2MB chunks.\n",
    "\n",
    "Please feel free to change `c_size` to fit your tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474d80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 12 chunks sum to 1000000 rows.\n"
     ]
    }
   ],
   "source": [
    "chunks = to_chunks('mydata.csv', 2)\n",
    "s = 0\n",
    "for chunk in chunks:\n",
    "    s += len(chunk)\n",
    "print('All', len(chunks), 'chunks sum to', s, 'rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f87ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()  # Close SQL connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
